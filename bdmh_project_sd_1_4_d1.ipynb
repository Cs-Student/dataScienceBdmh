{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4_NhtvEzVpb"
   },
   "source": [
    "# BDMH PROJECT\n",
    "## An Empirical Study of Machine Learning Algorithms for Cancer Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6IP0Y51LzVpd"
   },
   "source": [
    "#### Note\n",
    "----\n",
    "    Step 1) Place the 'GSE62054_series_matrix.txt', 'GSE98406_series_matrix.txt'\n",
    "    and 'scaling.py' in the same folder.\n",
    "    Step 2) Change the current directory to this new directory using the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MVdbltEKzVph"
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import scaling\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import classification_report, confusion_matrix ,accuracy_score,roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0DZxyipGzVpk"
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZGO0oc0KzVpl"
   },
   "outputs": [],
   "source": [
    "\n",
    "file_Thyroid=open(\"GSE62054_series_matrix.txt\",encoding='ISO-8859-1').read()\n",
    "data = file_Thyroid.split('\\n\\n')[2]\n",
    "data=data.split('\\n')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1149"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xt9nHxCYzVpo"
   },
   "outputs": [],
   "source": [
    "#splitting dataset into input data and output labels\n",
    "X=np.zeros((25,1146))\n",
    "for i in range(1,len(data)-1):\n",
    "    x=data[i].split('\\t')\n",
    "    #print(x)\n",
    "    for j in range(1,len(x)):\n",
    "#         print(i,\" \",j)\n",
    "        X[(j-1),(i-1)]=x[j]\n",
    "        \n",
    "Y=np.zeros(25)\n",
    "for i in range(0,25):\n",
    "    if i < 8:\n",
    "        Y[i] = 0\n",
    "    else:\n",
    "        Y[i] = 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "id": "0oomQ-tlzVpq",
    "outputId": "45d77471-c6e6-4ff6-fe2f-e92ea0c09ce3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X\\n', array([[5.26128859, 4.07453793, 3.21929761, ..., 4.99484292, 5.04675288,\n",
      "        4.33849959],\n",
      "       [5.09657112, 5.54199961, 3.14619765, ..., 4.06077457, 4.88185151,\n",
      "        4.57594889],\n",
      "       [5.37146322, 5.54199961, 2.85800437, ..., 4.88354725, 4.88291309,\n",
      "        4.54149244],\n",
      "       ...,\n",
      "       [5.10813134, 3.64184092, 5.38428995, ..., 4.16405064, 5.08635804,\n",
      "        4.88238879],\n",
      "       [5.09586229, 5.4187635 , 4.96860273, ..., 5.26612907, 4.83300648,\n",
      "        4.76127475],\n",
      "       [4.99992076, 5.29166851, 5.09225501, ..., 5.76627377, 4.91686286,\n",
      "        5.13710666]]), ', shape = ', (25, 1146))\n",
      "\n",
      "\n",
      "('Y\\n', array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1.]), ', shape = ', (25,))\n"
     ]
    }
   ],
   "source": [
    "print(\"X\\n\",X,\", shape = \",X.shape)\n",
    "print(\"\\n\")\n",
    "print(\"Y\\n\",Y,\", shape = \",Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1qdnNxACzVpt"
   },
   "outputs": [],
   "source": [
    "#seprating the test and train data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30,stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-byfnGO9zVpx"
   },
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "id": "FCwd7pEyzVpy",
    "outputId": "8de73328-88ae-43d7-ff99-706986538002"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    17\n",
      "0     8\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucky/anaconda3/envs/bdmh_prj_new/lib/python2.7/site-packages/matplotlib/font_manager.py:278: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  'Matplotlib is building the font cache using fc-list. '\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checking percentage of classes in labels\n",
    "YY = pd.Series(list(Y),dtype = 'int32')\n",
    "print(YY.value_counts())\n",
    "g = sns.countplot(YY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "gI_MT_6tzVp1",
    "outputId": "8a151357-e347-4643-f5f1-3098d9db71fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Checking null values in X : ', array([], shape=(0, 2), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking null values in X : \",np.argwhere(np.isnan(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UJbq1fSbB4sM"
   },
   "source": [
    "## Preprocesing Data\n",
    "## manually feature select using correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wu4sXiArCL_V"
   },
   "outputs": [],
   "source": [
    "#performing feature reduction\n",
    "def feature_reduction_correlation_train(XTrain,threshold):\n",
    "    rows, cols = XTrain.shape\n",
    "    df_XTrain  = pd.DataFrame(XTrain)\n",
    "    print(\"Train data Shape before feature removal : \",df_XTrain.shape)\n",
    "    correlation = df_XTrain.corr()\n",
    "    featureIndex = {}\n",
    "    for i in range(0,cols):\n",
    "        for j in range((i+1),cols):\n",
    "            if abs(correlation.iloc[i, j])>threshold:\n",
    "                if i in featureIndex.keys():\n",
    "                    featureIndex[i].append(j)\n",
    "                else:\n",
    "                    x = [j]\n",
    "                    featureIndex[i] = x\n",
    "                    \n",
    "    for x in featureIndex.keys():\n",
    "        df_XTrain.drop([x], axis = 1,inplace=True)\n",
    "    print(\"Train data Shape after feature removal : \",df_XTrain.shape)\n",
    "    XTrain = df_XTrain.to_numpy()\n",
    "    return XTrain, featureIndex\n",
    "\n",
    "def feature_reduction_correlation_test(XTest, featureIndex):\n",
    "    df_XTest=pd.DataFrame(XTest)\n",
    "    print(\"Test data shape before feature removal : \",XTest.shape)         \n",
    "    for x in featureIndex.keys():\n",
    "        df_XTest.drop([x], axis=1,inplace=True)\n",
    "    \n",
    "    XTest= df_XTest.to_numpy()\n",
    "    print(\"Test data shape after feature removal : \",XTest.shape)         \n",
    "    return XTest\n",
    "\n",
    "def feature_reduction_correlation(XTrain,XTest,threshold):\n",
    "    rows, cols = XTrain.shape\n",
    "    df_XTrain=pd.DataFrame(XTrain)\n",
    "    df_XTest=pd.DataFrame(XTest)\n",
    "    correlation = df_XTrain.corr()\n",
    "    print(\"Train data Shape before feature removal : \",df_XTrain.shape)\n",
    "\n",
    "\n",
    "    featureIndex={}\n",
    "    for i in range(0,cols):\n",
    "        for j in range((i+1),cols):\n",
    "            if abs(correlation.iloc[i, j])>threshold:\n",
    "                if i in featureIndex.keys():\n",
    "                    featureIndex[i].append(j)\n",
    "                else:\n",
    "                    x=[j]\n",
    "                    featureIndex[i]=x\n",
    "    for x in featureIndex.keys():\n",
    "        df_XTrain.drop([x], axis=1,inplace=True)\n",
    "        df_XTest.drop([x], axis=1,inplace=True)\n",
    "    XTrain= df_XTrain.to_numpy()\n",
    "    XTest= df_XTest.to_numpy()\n",
    "    print(\"Train data Shape after feature removal : \",df_XTrain.shape)\n",
    "    return XTrain,XTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature select using Select k best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif, SelectFdr, chi2\n",
    "def feature_reduction_selectkbest(x_train,y_train,x_test, k):\n",
    "    skb =  SelectKBest(chi2, k)\n",
    "   \n",
    "    X_new = skb.fit_transform(x_train, y_train)\n",
    "    X_new_test = skb.transform(x_test)\n",
    "    \n",
    "    return X_new,X_new_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 971
    },
    "colab_type": "code",
    "id": "GGJLqusTEFSE",
    "outputId": "1b36456d-2916-46d7-999f-357338993fe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Train data Shape before feature removal : ', (17, 1146))\n",
      "('Train data Shape after feature removal : ', (17, 1000))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'to_numpy'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0mTraceback (most recent call last)",
      "\u001B[0;32m<ipython-input-11-a0ec99a65171>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfi\u001B[0m  \u001B[0;34m=\u001B[0m \u001B[0mfeature_reduction_correlation_train\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m0.85\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mX_test\u001B[0m       \u001B[0;34m=\u001B[0m \u001B[0mfeature_reduction_correlation_test\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfi\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-9-d95a6fbe1ba3>\u001B[0m in \u001B[0;36mfeature_reduction_correlation_train\u001B[0;34m(XTrain, threshold)\u001B[0m\n\u001B[1;32m     19\u001B[0m         \u001B[0mdf_XTrain\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0minplace\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m     \u001B[0;32mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Train data Shape after feature removal : \"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdf_XTrain\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 21\u001B[0;31m     \u001B[0mXTrain\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf_XTrain\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_numpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     22\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mXTrain\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfeatureIndex\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/home/lucky/anaconda3/envs/bdmh_prj_new/lib/python2.7/site-packages/pandas/core/generic.pyc\u001B[0m in \u001B[0;36m__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   3612\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_info_axis\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3613\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3614\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mobject\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__getattribute__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3615\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3616\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__setattr__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'to_numpy'"
     ]
    }
   ],
   "source": [
    "X_train, fi  = feature_reduction_correlation_train(X_train,0.85)\n",
    "X_test       = feature_reduction_correlation_test(X_test, fi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "74D7vcIZ0AB1"
   },
   "source": [
    "## k fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SBhNEQ-cz_ZB"
   },
   "outputs": [],
   "source": [
    "def kCrossValidation(XTrain, YTrain, k, model_func):\n",
    "    rows, cols = XTrain.shape\n",
    "    kf = StratifiedKFold(n_splits=k, random_state=42, shuffle=False)\n",
    "    roc_list = []\n",
    "    accuracy_list = []\n",
    "    for itrain, itest in kf.split(XTrain,YTrain):\n",
    "        x_train, x_val = XTrain[itrain], XTrain[itest]\n",
    "        y_train, y_val = YTrain[itrain], YTrain[itest]\n",
    "        \n",
    "#         Xtr,XVal = feature_reduction_correlation(Xtr,XVal,0.85)\n",
    "        x_train, x_val = feature_reduction_selectkbest(x_train, y_train, x_val, 800)\n",
    "        \n",
    "        model, roc, accuracy = model_func(x_train, y_train, x_val,y_val)\n",
    "        \n",
    "        roc_list.append(roc)\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "    return roc_list, accuracy_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvCmIs1_zVp6"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JaG4a4ObzVp6"
   },
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "colab_type": "code",
    "id": "UvdwSBYyzVp7",
    "outputId": "6568c24a-1dc3-4782-f739-6129e9398a36"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.metrics import classification_report, confusion_matrix ,accuracy_score\n",
    "\n",
    "def LR_grid(X_train,y_train,X_test,y_test):\n",
    "    print(\"\\n--------Logistic Regression-----------\")\n",
    "    param_grid = { 'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'] }\n",
    "    \n",
    "    lr_clf = GridSearchCV(LogisticRegression(max_iter = 3000), param_grid, refit = True)\n",
    "    lr_clf.fit(X_train, y_train) \n",
    "    print(\"\\n<Best Params> :\",lr_clf.best_params_) \n",
    "    pred   = lr_clf.predict(X_test) \n",
    "    \n",
    "    # print classification report \n",
    "    print(\"\\n<Classification Report>\\n\",classification_report(y_test, pred)) \n",
    "    # print confusion matrix \n",
    "    print(\"\\n<Confusion Matrix>\\n\",confusion_matrix(y_test, pred)) \n",
    "    # print Acuracy\n",
    "    print(\"\\n<Accuracy> : \",accuracy_score(y_test, pred)) \n",
    "    return lr_clf ,roc_auc_score(y_test, pred),accuracy_score(y_test, pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BKKeiwZ4zVp9"
   },
   "source": [
    "### 2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9xvklvuzVp-"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import classification_report, confusion_matrix ,accuracy_score\n",
    "\n",
    "def SVM_grid(X_train,y_train,X_test,y_test):\n",
    "    print(\"\\n--------SVM-----------\")\n",
    "    param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],  \n",
    "                  'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "                  'kernel': ['linear', 'rbf', 'sigmoid']}  \n",
    "\n",
    "    grid = GridSearchCV(SVC(), param_grid, refit = True) \n",
    "\n",
    "    # fitting the model for grid search \n",
    "    grid.fit(X_train, y_train) \n",
    "    print(\"\\n<Best Params> :\",grid.best_params_) \n",
    "    grid_predictions = grid.predict(X_test) \n",
    "\n",
    "    # print classification report \n",
    "    print(\"\\n<Classification Report>\\n\",classification_report(y_test, grid_predictions)) \n",
    "    # print confusion matrix \n",
    "    print(\"\\n<Confusion Matrix>\\n\",confusion_matrix(y_test, grid_predictions)) \n",
    "    # print Acuracy\n",
    "    print(\"\\n<Accuracy> : \",accuracy_score(y_test, grid_predictions)) \n",
    "    return grid ,roc_auc_score(y_test, grid_predictions),accuracy_score(y_test, grid_predictions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9_z-hZG0zVqA"
   },
   "source": [
    "##  3. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "colab_type": "code",
    "id": "AEpj-PL-zVqB",
    "outputId": "d60bfefd-6de3-4c22-cf19-8821c4e958de"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def XGB_grid(X_train,y_train,X_test,y_test):\n",
    "    xg_clf = XGBClassifier(scoring='roc_auc')\n",
    "    parameters = {\n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [ 0.0001,0.001, 0.1, 0.2, 0.5],\n",
    "              'max_depth': [3,5,7,9],\n",
    "              'min_child_weight': [1,3,5,7],\n",
    "              'subsample': [0.8],\n",
    "              'n_estimators': [100],\n",
    "              'scale_pos_weight' : [1]\n",
    "              }\n",
    "    xg_clf = GridSearchCV(xg_clf, parameters, n_jobs=5, verbose=2, refit=True,scoring='roc_auc')\n",
    "    xg_clf.fit(X_train,y_train)\n",
    "    print(xg_clf.best_params_)\n",
    "    pred = xg_clf.predict(X_test)\n",
    "\n",
    "    print(\"\\n<Classification Report>\\n\",classification_report(y_test, pred))\n",
    "    # print confusion matrix\n",
    "    print(\"\\n,Confusion Matrix>\\n\",confusion_matrix(y_test, pred))\n",
    "    # print Acuracy\n",
    "    print(\"\\n<Accuracy> : \",accuracy_score(y_test, pred))\n",
    "    return xg_clf ,roc_auc_score(y_test, pred),accuracy_score(y_test, pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#parameters for random forest\n",
    "#----------------------\n",
    "#Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "#------------------------------\n",
    "def RF_grid(X_train,y_train,X_test,y_test):\n",
    "    print(\"\\n--------RF-----------\")\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "    grid = RandomizedSearchCV(estimator = RandomForestClassifier(), param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "    # fitting the model for grid search\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(\"\\n<Best Params> :\",grid.best_params_)\n",
    "    grid_predictions = grid.predict(X_test)\n",
    "    # print classification report\n",
    "    print(\"\\n<Classification Report>\\n\",classification_report(y_test, grid_predictions))\n",
    "    # print confusion matrix\n",
    "    print(\"\\n<Confusion Matrix>\\n\",confusion_matrix(y_test, grid_predictions))\n",
    "    # print Acuracy\n",
    "    print(\"\\n<Accuracy> : \",accuracy_score(y_test, grid_predictions))\n",
    "    return grid ,roc_auc_score(y_test, grid_predictions),accuracy_score(y_test, grid_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def NN_grid(X_train,y_train,X_test,y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile the keras model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit the keras model on the dataset\n",
    "    model.fit(X_train,y_train, epochs=150, batch_size=10,verbose=0)\n",
    "    # evaluate the keras model\n",
    "    _, accuracy = model.evaluate(X_test,y_test)\n",
    "    pred = model.predict_classes(X_test)\n",
    "    print('Accuracy: %.2f' % (accuracy*100))\n",
    "    return model ,roc_auc_score(y_test, pred),accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting performance of models\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "def plot_bar(accuracy_list, roc_list):\n",
    "    fig,ax = plt.subplots(1,1,figsize=(6,3),dpi=100,num=1)\n",
    "\n",
    "    Nbins = 5\n",
    "    Nbars = 2 # Number of bars (items) per bin\n",
    "\n",
    "    width = 1.0 /(Nbars+2)\n",
    "    ind = np.arange(Nbins)\n",
    "\n",
    "    # generate random data for now\n",
    "    np.random.seed(44328)\n",
    "    # Data = [np.random.uniform(size=Nbins) for i in range(Nbars)]\n",
    "    Data = [np.asarray(accuracy_list), np.asarray(roc_list)]\n",
    "    labels = ['acc', 'roc']\n",
    "\n",
    "    for ii,dat_item in enumerate(Data):\n",
    "        ax.bar(ind + (ii+1)*width,dat_item,width,label=labels[ii])\n",
    "\n",
    "    ax.set_xticks(ind+0.5)\n",
    "    ax.set_xticklabels(['fold 1','fold 2','fold 3','fold 4','fold 5'])\n",
    "    ax.legend()\n",
    "    ax.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Main function\n",
    "def main():\n",
    "    print(\"Models Available : \\n1. LR_grid\\n2. SVM_grid\\n3. XGB_grid\\n4. RF_grid\\n5. NN_grid\\n5. DNN_grid\")\n",
    "    model_func = int(input(\"Enter model id : \"))\n",
    "    func = [LR_grid, SVM_grid, XGB_grid,RF_grid, NN_grid]     # List of functions\n",
    "    model_func = func[model_func-1]                           # Select which function to call\n",
    "    roc_list,accuracy_list = kCrossValidation(X,Y,5,model_func)\n",
    "    # This prints the performance of each of the k fold\n",
    "    plot_bar(accuracy_list,roc_list)\n",
    "    print(\"MAUC :\",sum(roc_list) / len(roc_list))\n",
    "    print(\"MACr\",sum(accuracy_list) / len(accuracy_list))\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "0DZxyipGzVpk",
    "-byfnGO9zVpx",
    "UJbq1fSbB4sM",
    "KXltHDPQzVp3",
    "JaG4a4ObzVp6"
   ],
   "name": "bdmh_project_sd_1.1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python2",
   "language": "python",
   "display_name": "Python 2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}