{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "bdmh_project_sd_1_4_d1 (1).ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "pycharm-d529b1a4",
   "language": "python",
   "display_name": "PyCharm (bdmhprj1)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4_NhtvEzVpb"
   },
   "source": [
    "# BDMH PROJECT\n",
    "## An Empirical Study of Machine Learning Algorithms for Cancer Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6IP0Y51LzVpd"
   },
   "source": [
    "#### Note\n",
    "----\n",
    "    Step 1) Place the 'GSE62054_series_matrix.txt', 'GSE98406_series_matrix.txt'\n",
    "    and 'scaling.py' in the same folder.\n",
    "    Step 2) Change the current directory to this new directory using the cell below."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "MVdbltEKzVph",
    "colab": {}
   },
   "source": [
    "#imports\n",
    "#import scaling\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import classification_report, confusion_matrix ,accuracy_score,roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as plt"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0DZxyipGzVpk"
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "ZGO0oc0KzVpl",
    "colab": {}
   },
   "source": [
    "file_Thyroid=open(\"GSE62054_series_matrix.txt\",encoding='ISO-8859-1').read()\n",
    "data = file_Thyroid.split('\\n\\n')[2]\n",
    "data=data.split('\\n')   \n"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KNyq9bf3CpVh",
    "colab_type": "code",
    "outputId": "4326dfcb-3fec-40c1-d88e-f124098faf64",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1589944554857,
     "user_tz": -330,
     "elapsed": 1202,
     "user": {
      "displayName": "Snehil IIITD",
      "photoUrl": "",
      "userId": "15237628669278151435"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    }
   },
   "source": [
    "len(data)"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "1149"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "Xt9nHxCYzVpo",
    "colab": {}
   },
   "source": [
    "#splitting dataset into input data and output labels\n",
    "X=np.zeros((25,1146))\n",
    "for i in range(1,len(data)-1):\n",
    "    x=data[i].split('\\t')\n",
    "    #print(x)\n",
    "    for j in range(1,len(x)):\n",
    "#         print(i,\" \",j)\n",
    "        X[(j-1),(i-1)]=x[j]\n",
    "        \n",
    "Y=np.zeros(25)\n",
    "for i in range(0,25):\n",
    "    if i < 8:\n",
    "        Y[i] = 0\n",
    "    else:\n",
    "        Y[i] = 1\n",
    "        "
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "0oomQ-tlzVpq",
    "outputId": "1104b835-3a0b-42a4-89a5-013533c218f3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1589944565741,
     "user_tz": -330,
     "elapsed": 1101,
     "user": {
      "displayName": "Snehil IIITD",
      "photoUrl": "",
      "userId": "15237628669278151435"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    }
   },
   "source": [
    "print(\"X\\n\",X,\", shape = \",X.shape)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Y\\n\",Y,\", shape = \",Y.shape)\n"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      " [[5.26128859 4.07453793 3.21929761 ... 4.99484292 5.04675288 4.33849959]\n",
      " [5.09657112 5.54199961 3.14619765 ... 4.06077457 4.88185151 4.57594889]\n",
      " [5.37146322 5.54199961 2.85800437 ... 4.88354725 4.88291309 4.54149244]\n",
      " ...\n",
      " [5.10813134 3.64184092 5.38428995 ... 4.16405064 5.08635804 4.88238879]\n",
      " [5.09586229 5.4187635  4.96860273 ... 5.26612907 4.83300648 4.76127475]\n",
      " [4.99992076 5.29166851 5.09225501 ... 5.76627377 4.91686286 5.13710666]] , shape =  (25, 1146)\n",
      "\n",
      "\n",
      "Y\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1.] , shape =  (25,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-byfnGO9zVpx"
   },
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "FCwd7pEyzVpy",
    "outputId": "2368b2a0-fef1-4e6d-826e-ad16e7531626",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1589941591081,
     "user_tz": -330,
     "elapsed": 1681,
     "user": {
      "displayName": "Snehil IIITD",
      "photoUrl": "",
      "userId": "15237628669278151435"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    }
   },
   "source": [
    "#checking percentage of classes in labels\n",
    "YY = pd.Series(list(Y),dtype = 'int32')\n",
    "print(YY.value_counts())\n",
    "g = sns.countplot(YY)"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    17\n",
      "0     8\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "gI_MT_6tzVp1",
    "outputId": "e6510ed1-298f-42ae-92bb-664f52fd0769",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1589927393188,
     "user_tz": -330,
     "elapsed": 1109,
     "user": {
      "displayName": "Snehil IIITD",
      "photoUrl": "",
      "userId": "15237628669278151435"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    }
   },
   "source": [
    "print(\"Checking null values in X : \",np.argwhere(np.isnan(X)))"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking null values in X :  []\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UJbq1fSbB4sM"
   },
   "source": [
    "## Preprocesing Data\n",
    "## manually feature select using correlation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "wu4sXiArCL_V",
    "colab": {}
   },
   "source": [
    "#performing feature reduction\n",
    "def feature_reduction_correlation_train(XTrain,threshold):\n",
    "    rows, cols = XTrain.shape\n",
    "    df_XTrain  = pd.DataFrame(XTrain)\n",
    "    print(\"Train data Shape before feature removal : \",df_XTrain.shape)\n",
    "    correlation = df_XTrain.corr()\n",
    "    featureIndex = {}\n",
    "    for i in range(0,cols):\n",
    "        for j in range((i+1),cols):\n",
    "            if abs(correlation.iloc[i, j])>threshold:\n",
    "                if i in featureIndex.keys():\n",
    "                    featureIndex[i].append(j)\n",
    "                else:\n",
    "                    x = [j]\n",
    "                    featureIndex[i] = x\n",
    "                    \n",
    "    for x in featureIndex.keys():\n",
    "        df_XTrain.drop([x], axis = 1,inplace=True)\n",
    "    print(\"Train data Shape after feature removal : \",df_XTrain.shape)\n",
    "    XTrain = df_XTrain.to_numpy()\n",
    "    return XTrain, featureIndex\n",
    "\n",
    "def feature_reduction_correlation_test(XTest, featureIndex):\n",
    "    df_XTest=pd.DataFrame(XTest)\n",
    "    print(\"Test data shape before feature removal : \",XTest.shape)         \n",
    "    for x in featureIndex.keys():\n",
    "        df_XTest.drop([x], axis=1,inplace=True)\n",
    "    \n",
    "    XTest= df_XTest.to_numpy()\n",
    "    print(\"Test data shape after feature removal : \",XTest.shape)         \n",
    "    return XTest\n",
    "\n",
    "def feature_reduction_correlation(XTrain,XTest,threshold):\n",
    "    rows, cols = XTrain.shape\n",
    "    df_XTrain=pd.DataFrame(XTrain)\n",
    "    df_XTest=pd.DataFrame(XTest)\n",
    "    correlation = df_XTrain.corr()\n",
    "    print(\"Train data Shape before feature removal : \",df_XTrain.shape)\n",
    "\n",
    "\n",
    "    featureIndex={}\n",
    "    for i in range(0,cols):\n",
    "        for j in range((i+1),cols):\n",
    "            if abs(correlation.iloc[i, j])>threshold:\n",
    "                if i in featureIndex.keys():\n",
    "                    featureIndex[i].append(j)\n",
    "                else:\n",
    "                    x=[j]\n",
    "                    featureIndex[i]=x\n",
    "    for x in featureIndex.keys():\n",
    "        df_XTrain.drop([x], axis=1,inplace=True)\n",
    "        df_XTest.drop([x], axis=1,inplace=True)\n",
    "    XTrain= df_XTrain.to_numpy()\n",
    "    XTest= df_XTest.to_numpy()\n",
    "    print(\"Train data Shape after feature removal : \",df_XTrain.shape)\n",
    "    return XTrain,XTest"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIWrBgXnCpV5",
    "colab_type": "text"
   },
   "source": [
    "## feature select using Select k best"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xXd7SaTKCpV6",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif, SelectFdr, chi2\n",
    "def feature_reduction_selectkbest(x_train,y_train,x_test, k):\n",
    "    skb =  SelectKBest(chi2, k)\n",
    "   \n",
    "    X_new = skb.fit_transform(x_train, y_train)\n",
    "    X_new_test = skb.transform(x_test)\n",
    "    \n",
    "    return X_new,X_new_test"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "GGJLqusTEFSE",
    "outputId": "39df6cdc-de89-42f9-9115-e2c3f1f1df50",
    "executionInfo": {
     "status": "error",
     "timestamp": 1589927475991,
     "user_tz": -330,
     "elapsed": 1092,
     "user": {
      "displayName": "Snehil IIITD",
      "photoUrl": "",
      "userId": "15237628669278151435"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    }
   },
   "source": [
    "# X_train, fi  = feature_reduction_correlation_train(X_train,0.85)\n",
    "# X_test       = feature_reduction_correlation_test(X_test, fi)"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "74D7vcIZ0AB1"
   },
   "source": [
    "## k fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "SBhNEQ-cz_ZB",
    "colab": {}
   },
   "source": [
    "def kCrossValidation(XTrain, YTrain, k, model_func,flag,threshold):\n",
    "    rows, cols = XTrain.shape\n",
    "    kf = StratifiedKFold(n_splits=k, random_state=42, shuffle=False)\n",
    "    roc_list = []\n",
    "    accuracy_list = []\n",
    "    for itrain, itest in kf.split(XTrain,YTrain):\n",
    "        x_train, x_val = XTrain[itrain], XTrain[itest]\n",
    "        y_train, y_val = YTrain[itrain], YTrain[itest]\n",
    "        \n",
    "        if flag==0:\n",
    "          Xtr,XVal = feature_reduction_correlation(x_train,x_val,threshold)\n",
    "\n",
    "        else:\n",
    "          x_train, x_val = feature_reduction_selectkbest(x_train, y_train, x_val,threshold)\n",
    "        \n",
    "        roc, accuracy = model_func(x_train, y_train, x_val,y_val)\n",
    "        \n",
    "        roc_list.append(roc)\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "    return roc_list, accuracy_list"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jvCmIs1_zVp6"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JaG4a4ObzVp6"
   },
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "UvdwSBYyzVp7",
    "colab": {}
   },
   "source": [
    "\n",
    "def LR_grid(X_train,y_train,X_test,y_test):\n",
    "    print(\"\\n--------Logistic Regression-----------\")\n",
    "    param_grid = { 'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'] }\n",
    "    \n",
    "    lr_clf = GridSearchCV(LogisticRegression(max_iter = 3000), param_grid, refit = True)\n",
    "    lr_clf.fit(X_train, y_train) \n",
    "    print(\"\\n<Best Params> :\",lr_clf.best_params_) \n",
    "    pred   = lr_clf.predict(X_test) \n",
    "    \n",
    "    # print classification report \n",
    "    print(\"\\n<Classification Report>\\n\",classification_report(y_test, pred)) \n",
    "    # print confusion matrix \n",
    "    print(\"\\n<Confusion Matrix>\\n\",confusion_matrix(y_test, pred)) \n",
    "    # print Acuracy\n",
    "    print(\"\\n<Accuracy> : \",accuracy_score(y_test, pred)) \n",
    "    return roc_auc_score(y_test, pred),accuracy_score(y_test, pred)\n",
    "\n",
    "\n"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BKKeiwZ4zVp9"
   },
   "source": [
    "### 2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "B9xvklvuzVp-",
    "colab": {}
   },
   "source": [
    "\n",
    "\n",
    "def SVM_grid(X_train,y_train,X_test,y_test):\n",
    "    print(\"\\n--------SVM-----------\")\n",
    "    param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],  \n",
    "                  'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "                  'kernel': ['linear', 'rbf', 'sigmoid']}  \n",
    "\n",
    "    grid = GridSearchCV(SVC(), param_grid, refit = True) \n",
    "\n",
    "    # fitting the model for grid search \n",
    "    grid.fit(X_train, y_train) \n",
    "    print(\"\\n<Best Params> :\",grid.best_params_) \n",
    "    grid_predictions = grid.predict(X_test) \n",
    "\n",
    "    # print classification report \n",
    "    print(\"\\n<Classification Report>\\n\",classification_report(y_test, grid_predictions)) \n",
    "    # print confusion matrix \n",
    "    print(\"\\n<Confusion Matrix>\\n\",confusion_matrix(y_test, grid_predictions)) \n",
    "    # print Acuracy\n",
    "    print(\"\\n<Accuracy> : \",accuracy_score(y_test, grid_predictions)) \n",
    "    return roc_auc_score(y_test, grid_predictions),accuracy_score(y_test, grid_predictions)\n",
    "\n",
    "\n"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9_z-hZG0zVqA"
   },
   "source": [
    "##  3. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "AEpj-PL-zVqB",
    "colab": {}
   },
   "source": [
    "\n",
    "\n",
    "def XGB_grid(X_train,y_train,X_test,y_test):\n",
    "    xg_clf = XGBClassifier(scoring='roc_auc')\n",
    "    parameters = {\n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [ 0.0001,0.001, 0.1, 0.2, 0.5],\n",
    "              'max_depth': [3,5,7,9],\n",
    "              'min_child_weight': [1,3,5,7],\n",
    "              'subsample': [0.8],\n",
    "              'n_estimators': [100],\n",
    "              'scale_pos_weight' : [1]\n",
    "              }\n",
    "    xg_clf = GridSearchCV(xg_clf, parameters, n_jobs=5, verbose=2, refit=True,scoring='roc_auc')\n",
    "    xg_clf.fit(X_train,y_train)\n",
    "    print(xg_clf.best_params_)\n",
    "    pred = xg_clf.predict(X_test)\n",
    "\n",
    "    print(\"\\n<Classification Report>\\n\",classification_report(y_test, pred))\n",
    "    # print confusion matrix\n",
    "    print(\"\\n,Confusion Matrix>\\n\",confusion_matrix(y_test, pred))\n",
    "    # print Acuracy\n",
    "    print(\"\\n<Accuracy> : \",accuracy_score(y_test, pred))\n",
    "    return roc_auc_score(y_test, pred),accuracy_score(y_test, pred)\n",
    "\n",
    "\n"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NoMJR35ApobD",
    "colab_type": "text"
   },
   "source": [
    "#Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "D61tdmeEpiIs",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "def NB(Xtrain,Ytrain,Xtest,Ytest):\n",
    "  gnb = GaussianNB()\n",
    "  pred = gnb.fit(Xtrain,Ytrain).predict(Xtest)\n",
    "  print(\"\\n<Classification Report>\\n\",classification_report(Ytest, pred))\n",
    "  # print confusion matrix\n",
    "  print(\"\\n,Confusion Matrix>\\n\",confusion_matrix(Ytest, pred))\n",
    "  # print Acuracy\n",
    "  print(\"\\n<Accuracy> : \",accuracy_score(Ytest, pred))\n",
    "  return roc_auc_score(Ytest, pred),accuracy_score(Ytest, pred)\n",
    "\n"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYBVcE0zGyhO",
    "colab_type": "text"
   },
   "source": [
    "#Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sYz1jy2DGn7N",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def ADB_grid(X_train,y_train,X_test,y_test):\n",
    " ada_boost = AdaBoostClassifier()\n",
    " \n",
    " grid_params = {  \n",
    "                  'learning_rate': [ 0.0001,0.001, 0.1, 0.2, 0.5],\n",
    "                  'n_estimators': [100,200,300]}\n",
    " adb_grid = GridSearchCV(ada_boost, param_grid = grid_params, scoring='roc_auc', cv=5, n_jobs = -1)\n",
    " adb_grid.fit(X_train,y_train)\n",
    " print(adb_grid.best_params_)\n",
    " pred =  adb_grid.predict(X_test)\n",
    "\n",
    " print(\"Classification Report : \",classification_report(y_test, pred))\n",
    " # print confusion matrix\n",
    " print(\"Confusion Matrix : \",confusion_matrix(y_test, pred))\n",
    " # print Acuracy\n",
    " print(\"Accuracy : \",accuracy_score(y_test, pred))\n",
    " return roc_auc_score(y_test, pred),accuracy_score(y_test, pred)\n"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MVgTqhk7CpWP",
    "colab_type": "text"
   },
   "source": [
    "## 4. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_CNAa80VCpWQ",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "#parameters for random forest\n",
    "#----------------------\n",
    "#Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "#------------------------------\n",
    "def RF_grid(X_train,y_train,X_test,y_test):\n",
    "    print(\"\\n--------RF-----------\")\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "    grid = RandomizedSearchCV(estimator = RandomForestClassifier(), param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "    # fitting the model for grid search\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(\"\\n<Best Params> :\",grid.best_params_)\n",
    "    grid_predictions = grid.predict(X_test)\n",
    "    # print classification report\n",
    "    print(\"\\n<Classification Report>\\n\",classification_report(y_test, grid_predictions))\n",
    "    # print confusion matrix\n",
    "    print(\"\\n<Confusion Matrix>\\n\",confusion_matrix(y_test, grid_predictions))\n",
    "    # print Acuracy\n",
    "    print(\"\\n<Accuracy> : \",accuracy_score(y_test, grid_predictions))\n",
    "    return roc_auc_score(y_test, grid_predictions),accuracy_score(y_test, grid_predictions)\n"
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4D2KovnhCpWT",
    "colab_type": "text"
   },
   "source": [
    "## 5. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KnBO8n1sCpWT",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def NN_grid(X_train,y_train,X_test,y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile the keras model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit the keras model on the dataset\n",
    "    model.fit(X_train,y_train, epochs=150, batch_size=10,verbose=0)\n",
    "    # evaluate the keras model\n",
    "    _, accuracy = model.evaluate(X_test,y_test)\n",
    "    pred = model.predict_classes(X_test)\n",
    "    print('Accuracy: %.2f' % (accuracy*100))\n",
    "    return roc_auc_score(y_test, pred),accuracy_score(y_test, pred)"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "P2cn7XYuCpWW",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#plotting performance of models\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "def plot_bar(accuracy_list, roc_list):\n",
    "    fig,ax = plt.subplots(1,1,figsize=(6,3),dpi=100,num=1)\n",
    "\n",
    "    Nbins = 5\n",
    "    Nbars = 2 # Number of bars (items) per bin\n",
    "\n",
    "    width = 1.0 /(Nbars+2)\n",
    "    ind = np.arange(Nbins)\n",
    "\n",
    "    # generate random data for now\n",
    "    np.random.seed(44328)\n",
    "    # Data = [np.random.uniform(size=Nbins) for i in range(Nbars)]\n",
    "    Data = [np.asarray(accuracy_list), np.asarray(roc_list)]\n",
    "    labels = ['acc', 'roc']\n",
    "\n",
    "    for ii,dat_item in enumerate(Data):\n",
    "        ax.bar(ind + (ii+1)*width,dat_item,width,label=labels[ii])\n",
    "\n",
    "    ax.set_xticks(ind+0.5)\n",
    "    ax.set_xticklabels(['fold 1','fold 2','fold 3','fold 4','fold 5'])\n",
    "    ax.legend()\n",
    "    ax.plot()"
   ],
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "-8ZhuuljCpWY",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#Main function\n",
    "def main_thyroid():\n",
    "    print(\"Models Available : \\n1. LR_grid\\n2. SVM_grid\\n3. XGB_grid\\n4. RF_grid\\n5. NN_grid\\n6. NB\\n7. ADB_grid\")\n",
    "    model_func = int(input(\"Enter model id : \"))\n",
    "    flag=int(input(\"Enter feature selection technique: \\n0 for correlation \\n1 for selectKbest\"))\n",
    "    threshold=int(input(\"Enter threshold:\"))\n",
    "    func = [LR_grid, SVM_grid, XGB_grid,RF_grid, NN_grid,NB,ADB_grid]     # List of functions\n",
    "    model_func = func[model_func-1]                           # Select which function to call\n",
    "    roc_list,accuracy_list = kCrossValidation(X,Y,5,model_func,flag,threshold)\n",
    "    # This prints the performance of each of the k fold\n",
    "    plot_bar(accuracy_list,roc_list)\n",
    "    print(\"MAUC :\",sum(roc_list) / len(roc_list))\n",
    "    print(\"MAccuracy\",sum(accuracy_list) / len(accuracy_list))"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def plot_model(mauc_list, macr_list, model_names):\n",
    "    fig,ax = plt.subplots(1,1,figsize=(6,3),dpi=100,num=1)\n",
    "\n",
    "    Nbins = len(mauc_list)\n",
    "    Nbars = 2 # Number of bars (items) per bin\n",
    "\n",
    "    width = 1.0 /(Nbars+2)\n",
    "    ind = np.arange(Nbins)\n",
    "\n",
    "    # generate random data for now\n",
    "    np.random.seed(44328)\n",
    "    # Data = [np.random.uniform(size=Nbins) for i in range(Nbars)]\n",
    "    Data = [np.asarray(mauc_list), np.asarray(macr_list)]\n",
    "    labels = ['acc', 'roc']\n",
    "\n",
    "    for ii,dat_item in enumerate(Data):\n",
    "        ax.bar(ind + (ii+1)*width,dat_item,width,label=labels[ii])\n",
    "\n",
    "    ax.set_xticks(ind+0.5)\n",
    "    ax.set_xticklabels(model_names)\n",
    "    ax.legend()\n",
    "    ax.plot()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# model_name = [\"Logistic Regression\", \"SVM\", \"XGBoost\", \"Random Forest\", \"Neural Network\",\"Naive Bayes\" , \"ADB\"]\n",
    "# func = [LR_grid, SVM_grid, XGB_grid,RF_grid, NN_grid,NB,ADB_grid]     # List of functions\n",
    "# mauc = []\n",
    "# macr = []\n",
    "# count = 0\n",
    "# for i in func:\n",
    "#     print(\"------------------------ \"+model_name[count]+\" -----------------------------\")\n",
    "#     roc_list,accuracy_list = kCrossValidation(X,Y,5,i,1,800 )\n",
    "#     # This prints the performance of each of the k fold\n",
    "#     print(\"------------------------\"+\"Graph of \"+model_name[count]+\"-----------------------------\")\n",
    "#     count+=1\n",
    "#     plot_bar(accuracy_list,roc_list)\n",
    "#     avgMAUC = sum(roc_list) / len(roc_list)\n",
    "#     avgMACr =  sum(accuracy_list) / len(accuracy_list)\n",
    "#     mauc.append(avgMAUC)\n",
    "#     macr.append(avgMACr)\n",
    "#     print(\"final MAUC :\",avgMAUC)\n",
    "#     print(\"final MACr\",avgMACr)\n",
    "#     plt.pause(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kMQvqc0T10Ag",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# model_name = [\"LR\", \"SVM\", \"XGB\", \"RF\", \"NN\", \"NB\" , \"ADB\"]\n",
    "# plot_model(mauc,macr,model_name)\n",
    "#"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# print(mauc)\n",
    "# print(macr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models Available : \n",
      "1. LR_grid\n",
      "2. SVM_grid\n",
      "3. XGB_grid\n",
      "4. RF_grid\n",
      "5. NN_grid\n",
      "6. NB\n",
      "7. ADB_grid\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-26-252eede00091>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmain_thyroid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-21-a94f7a96a908>\u001B[0m in \u001B[0;36mmain_thyroid\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mmain_thyroid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Models Available : \\n1. LR_grid\\n2. SVM_grid\\n3. XGB_grid\\n4. RF_grid\\n5. NN_grid\\n6. NB\\n7. ADB_grid\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m     \u001B[0mmodel_func\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Enter model id : \"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m     \u001B[0mflag\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Enter feature selection technique: \\n0 for correlation \\n1 for selectKbest\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0mthreshold\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Enter threshold:\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "main_thyroid()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}