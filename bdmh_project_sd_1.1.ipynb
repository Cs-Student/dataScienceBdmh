{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# BDMH PROJECT\n",
    "## An Empirical Study of Machine Learning Algorithms for Cancer Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Note\n",
    "----\n",
    "    Step 1) Place the 'GSE62054_series_matrix.txt',\n",
    "    'GSE98406_series_matrix.txt' and 'scaling.py' in the same folder.\n",
    "    Step 2) Change the current directory to this new directory using the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cd C:\\Users\\shubh\\Desktop\\IIITD\\Sem2\\BDMH\\project\\Dataset\\matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scaling\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix ,accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_Thyroid=open(\"GSE62054_series_matrix.txt\",encoding='ISO-8859-1').read()\n",
    "data = file_Thyroid.split('\\n\\n')[2]\n",
    "data=data.split('\\n')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.zeros((25,1146))\n",
    "for i in range(1,len(data)-1):\n",
    "    x=data[i].split('\\t')\n",
    "    #print(x)\n",
    "    for j in range(1,len(x)):\n",
    "#         print(i,\" \",j)\n",
    "        X[(j-1),(i-1)]=x[j]\n",
    "        \n",
    "Y=np.zeros(25)\n",
    "for i in range(0,25):\n",
    "    if i < 8:\n",
    "        Y[i] = 0\n",
    "    else:\n",
    "        Y[i] = 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      " [[5.26128859 4.07453793 3.21929761 ... 4.99484292 5.04675288 4.33849959]\n",
      " [5.09657112 5.54199961 3.14619765 ... 4.06077457 4.88185151 4.57594889]\n",
      " [5.37146322 5.54199961 2.85800437 ... 4.88354725 4.88291309 4.54149244]\n",
      " ...\n",
      " [5.10813134 3.64184092 5.38428995 ... 4.16405064 5.08635804 4.88238879]\n",
      " [5.09586229 5.4187635  4.96860273 ... 5.26612907 4.83300648 4.76127475]\n",
      " [4.99992076 5.29166851 5.09225501 ... 5.76627377 4.91686286 5.13710666]] , shape =  (25, 1146)\n",
      "\n",
      "\n",
      "Y\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1.] , shape =  (25,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X\\n\",X,\", shape = \",X.shape)\n",
    "print(\"\\n\")\n",
    "print(\"Y\\n\",Y,\", shape = \",Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=42,stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    17\n",
      "0     8\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "YY = pd.Series(list(Y),dtype = 'int32')\n",
    "print(YY.value_counts())\n",
    "# g = sns.countplot(YY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking null values in X :  []\n"
     ]
    }
   ],
   "source": [
    "print(\"Checking null values in X : \",np.argwhere(np.isnan(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SZ = Scaled Z Score\n",
    "# SMM = Scale MinMax\n",
    "\n",
    "X_train_SZ, m, s  = scaling.ZScoreScalingTrain(X_train)\n",
    "X_test_SZ         = scaling.ZScoreScalingTest(X_test,m,s)\n",
    "    \n",
    "X_train_SMM, m, s = scaling.MinMaxScalingTrain(X_train)\n",
    "X_test_SMM        = scaling.MinMaxScalingTest(X_test,m,s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.metrics import classification_report, confusion_matrix ,accuracy_score\n",
    "\n",
    "def LR_grid(X_train,y_train,X_test,y_test):\n",
    "    print(\"\\n--------Logistic Regression-----------\")\n",
    "    param_grid = { 'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'] }\n",
    "    \n",
    "    lr_clf = GridSearchCV(LogisticRegression(max_iter = 3000), param_grid, refit = True)\n",
    "    lr_clf.fit(X_train, y_train) \n",
    "    print(\"\\n<Best Params> :\",lr_clf.best_params_) \n",
    "    pred   = lr_clf.predict(X_test) \n",
    "    \n",
    "    # print classification report \n",
    "    print(\"\\n<Classification Report>\\n\",classification_report(y_test, pred)) \n",
    "    # print confusion matrix \n",
    "    print(\"\\n<Confusion Matrix>\\n\",confusion_matrix(y_test, pred)) \n",
    "    # print Acuracy\n",
    "    print(\"\\n<Accuracy> : \",accuracy_score(y_test, pred)) \n",
    "    return lr_clf\n",
    "\n",
    "\n",
    "LR_SZ = LR_grid(X_train_SZ,y_train,X_test_SZ,y_test)\n",
    "\n",
    "LR_SMM = LR_grid(X_train_SMM,y_train,X_test_SMM,y_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import classification_report, confusion_matrix ,accuracy_score\n",
    "\n",
    "def SVM_grid(X_train,y_train,X_test,y_test):\n",
    "    print(\"\\n--------SVM-----------\")\n",
    "    param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "                  'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "                  'kernel': ['linear', 'rbf', 'sigmoid']}  \n",
    "\n",
    "    grid = GridSearchCV(SVC(), param_grid, refit = True) \n",
    "\n",
    "    # fitting the model for grid search \n",
    "    grid.fit(X_train, y_train) \n",
    "    print(\"\\n<Best Params> :\",grid.best_params_) \n",
    "    grid_predictions = grid.predict(X_test) \n",
    "\n",
    "    # print classification report \n",
    "    print(\"\\n<Classification Report>\\n\",classification_report(y_test, grid_predictions)) \n",
    "    # print confusion matrix \n",
    "    print(\"\\n<Confusion Matrix>\\n\",confusion_matrix(y_test, grid_predictions)) \n",
    "    # print Acuracy\n",
    "    print(\"\\n<Accuracy> : \",accuracy_score(y_test, grid_predictions)) \n",
    "    return grid\n",
    "\n",
    "\n",
    "SVM_SZ = SVM_grid(X_train_SZ,y_train,X_test_SZ,y_test)\n",
    "\n",
    "SVM_SMM = SVM_grid(X_train_SMM,y_train,X_test_SMM,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# data_dmatrix = xgb.DMatrix(data=X,label=Y)\n",
    "\n",
    "def XGB_classifier(X_train,y_train,X_test,y_test):\n",
    "    xg_clf = XGBClassifier()\n",
    "    parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.05], \n",
    "              'max_depth': [5,6,7,8,9,10],\n",
    "              'min_child_weight': [11],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.8],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [5,1000], \n",
    "              }\n",
    "    xg_clf = GridSearchCV(xg_clf, parameters, n_jobs=5, verbose=2, refit=True)\n",
    "    xg_clf.fit(X_train,y_train)\n",
    "\n",
    "    pred = xg_clf.predict(X_test)\n",
    "\n",
    "    print(\"\\n<Classification Report>\\n\",classification_report(y_test, pred)) \n",
    "    # print confusion matrix \n",
    "    print(\"\\n,Confusion Matrix>\\n\",confusion_matrix(y_test, pred)) \n",
    "    # print Acuracy\n",
    "    print(\"\\n<Accuracy> : \",accuracy_score(y_test, pred)) \n",
    "    \n",
    "XGB_SZ = XGB_classifier(X_train_SZ,y_train,X_test_SZ,y_test)\n",
    "\n",
    "XGB_SMM = XGB_classifier(X_train_SMM,y_train,X_test_SMM,y_test)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<Accfdsfuracy> :  0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "model = RandomForestClassifier(n_estimators=100,\n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt')\n",
    "# Fit on training data\n",
    "model.fit(X_train, y_train)\n",
    "rf_predictions = model.predict(X_test)\n",
    "# Probabilities for each class\n",
    "\n",
    "print(\"\\n<Accfdsfuracy> : \",accuracy_score(y_test, rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------RF-----------\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "\n",
      "<Best Params> : {'n_estimators': 1200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': False}\n",
      "\n",
      "<Classification Report>\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.33      0.50         3\n",
      "         1.0       0.71      1.00      0.83         5\n",
      "\n",
      "    accuracy                           0.75         8\n",
      "   macro avg       0.86      0.67      0.67         8\n",
      "weighted avg       0.82      0.75      0.71         8\n",
      "\n",
      "\n",
      "<Confusion Matrix>\n",
      " [[1 2]\n",
      " [0 5]]\n",
      "\n",
      "<Accuracy> :  0.75\n",
      "\n",
      "--------RF-----------\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "\n",
      "<Best Params> : {'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': False}\n",
      "\n",
      "<Classification Report>\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.33      0.50         3\n",
      "         1.0       0.71      1.00      0.83         5\n",
      "\n",
      "    accuracy                           0.75         8\n",
      "   macro avg       0.86      0.67      0.67         8\n",
      "weighted avg       0.82      0.75      0.71         8\n",
      "\n",
      "\n",
      "<Confusion Matrix>\n",
      " [[1 2]\n",
      " [0 5]]\n",
      "\n",
      "<Accuracy> :  0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   38.3s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  5.3min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  4.5min finished\n"
     ]
    }
   ],
   "source": [
    "#parameters for random forest\n",
    "#----------------------\n",
    "#Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "#------------------------------\n",
    "def RF_grid(X_train,y_train,X_test,y_test):\n",
    "    print(\"\\n--------RF-----------\")\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "    grid = RandomizedSearchCV(estimator = RandomForestClassifier(), param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "    # fitting the model for grid search\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(\"\\n<Best Params> :\",grid.best_params_)\n",
    "    grid_predictions = grid.predict(X_test)\n",
    "    # print classification report\n",
    "    print(\"\\n<Classification Report>\\n\",classification_report(y_test, grid_predictions))\n",
    "    # print confusion matrix\n",
    "    print(\"\\n<Confusion Matrix>\\n\",confusion_matrix(y_test, grid_predictions))\n",
    "    # print Acuracy\n",
    "    print(\"\\n<Accuracy> : \",accuracy_score(y_test, grid_predictions))\n",
    "    return grid\n",
    "RF_SZ = RF_grid(X_train_SZ,y_train,X_test_SZ,y_test)\n",
    "\n",
    "RF_SMM = RF_grid(X_train_SMM,y_train,X_test_SMM,y_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "#implementing k fold for cross validation\n",
    "def cross_validation(splits,func):\n",
    "    skf = StratifiedKFold(n_splits=splits)\n",
    "    for train_index, test_index in skf.split(X, Y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "        X_train_SZ, m, s  = scaling.ZScoreScalingTrain(X_train)\n",
    "        X_test_SZ         = scaling.ZScoreScalingTest(X_test,m,s)\n",
    "        X_train_SMM, m, s = scaling.MinMaxScalingTrain(X_train)\n",
    "        X_test_SMM        = scaling.MinMaxScalingTest(X_test,m,s)\n",
    "        RF_SZ = func(X_train_SZ,y_train,X_test_SZ,y_test)\n",
    "        RF_SMM = func(X_train_SMM,y_train,X_test_SMM,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------RF-----------\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "\n",
      "<Best Params> : {'n_estimators': 600, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 60, 'bootstrap': False}\n",
      "\n",
      "<Classification Report>\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         2\n",
      "         1.0       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         5\n",
      "   macro avg       1.00      1.00      1.00         5\n",
      "weighted avg       1.00      1.00      1.00         5\n",
      "\n",
      "\n",
      "<Confusion Matrix>\n",
      " [[2 0]\n",
      " [0 3]]\n",
      "\n",
      "<Accuracy> :  1.0\n",
      "\n",
      "--------RF-----------\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "\n",
      "<Best Params> : {'n_estimators': 600, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 60, 'bootstrap': False}\n",
      "\n",
      "<Classification Report>\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         2\n",
      "         1.0       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         5\n",
      "   macro avg       1.00      1.00      1.00         5\n",
      "weighted avg       1.00      1.00      1.00         5\n",
      "\n",
      "\n",
      "<Confusion Matrix>\n",
      " [[2 0]\n",
      " [0 3]]\n",
      "\n",
      "<Accuracy> :  1.0\n",
      "\n",
      "--------RF-----------\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "\n",
      "<Best Params> : {'n_estimators': 1200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': False}\n",
      "\n",
      "<Classification Report>\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.50      0.67         2\n",
      "         1.0       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.80         5\n",
      "   macro avg       0.88      0.75      0.76         5\n",
      "weighted avg       0.85      0.80      0.78         5\n",
      "\n",
      "\n",
      "<Confusion Matrix>\n",
      " [[1 1]\n",
      " [0 3]]\n",
      "\n",
      "<Accuracy> :  0.8\n",
      "\n",
      "--------RF-----------\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  4.8min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  4.1min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   29.1s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  4.0min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   28.0s\n"
     ]
    }
   ],
   "source": [
    "cross_validation(5,RF_grid)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}